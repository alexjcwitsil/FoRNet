
###############################
## PREPROCESSING AND SCALING ##
###############################

def scale_features(unscaled_features):

    ## remove any nan values
    unscaled_features = unscaled_features[~np.isnan(unscaled_features).any(axis=1)]

    # isolate the features and the labels from the dataframe
    features_unnorm = unscaled_features.drop(labels='category_id',axis=1)
    ##labels_raw = unscaled_features['category_id']

    ## reshape y from a column 'vector' to row 'vector'
    ##labels_raw = np.array(labels_raw).reshape(len(labels_raw),1)

    ## Normalize the data (mean=0 and std=1)
    sc = StandardScaler()
    features = sc.fit_transform(features_unnorm)

    # one hot encode the raw labels
    ohe = OneHotEncoder()
    labels = ohe.fit_transform(labels_raw).toarray()

    ## split the data into a training and test set
    features_train, features_test,labels_train,labels_test = train_test_split(features,labels,test_size = 0.1)
